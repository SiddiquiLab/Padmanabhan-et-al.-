# -*- coding: utf-8 -*-
"""Step 1) Data_into_range_Flag_RIM12_Homer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rdGTEmQWI1ZBAqxeyEIahzK6ybk0m5zl

Run to update

**Run to make sure program is up to date**

**Import** **Files**
"""

import pandas as pd
import numpy as np
import os
from google.colab import data_table, files
import math

"""**All data excel/xlsx files that needs to be processed should be in one folder**

id_name is the name the file will be saved as, factor is the expansion factor, folder_path is the folder name used
"""

id_name = "G91L_s6h1_SR_1_"
factor = 3.9698
folder_path = "Data"

#enrichment analysis variables
proteins = ['Flag-Homer', 'Flag-RIM']
enrichment_analysis = True
download_range = False

#Angle analysis was not used in this protein data set
use_angle_analysis = False
angle_flag = 180
angle_flag_lower = 0
angle_Homer = 180
angle_RIM = 180

all_flag_rim = []
close_flag_rim = []
all_flag_homer = []
close_flag_homer = []
all_rim = []
all_homer = []
all_rim_complex = []
all_homer_complex = []

"""This will loop through your data folder, and create a list of file names for the program to process"""

def get_file_names_in_folder(folder_path):

  file_names = []
  if os.path.exists(folder_path):
    for filename in os.listdir(folder_path):
      file_path = os.path.join(folder_path, filename)
      if os.path.isfile(file_path):
        file_names.append(filename)
  return file_names

file_list = get_file_names_in_folder(folder_path)
length = len(file_list)

mean1_df = []
mean2_df = []
mean3_df = []
all_df_1_grouped = []
all_df_2_grouped = []
all_df_3_grouped = []

"""This will take all the data files, convert the distances with the expansion factor, and organize the min distances in range bins of 10nm"""

for n in range(0,length):
  df = pd.read_csv(f'{folder_path}/{file_list[n]}')

  object1_name = []
  object2_name = []

  object1 = df['Object1'].unique()

  #Flag
  object1_1 = object1[0]
  #Homer
  object1_2 = object1[1]


  arr1_1 = object1_1.split(" ", 2);
  object1_1_name = arr1_1[0]
  object1_name.append(object1_1_name)

  arr1_2 = object1_2.split(" ", 2);
  object1_2_name = arr1_2[0]
  object1_name.append(object1_2_name)

  object2 = df['Object2'].unique()

  #Homer
  object2_1 = object2[0]
  #RIM
  object2_2 = object2[1]


  arr2_1 = object2_1.split(" ", 2);
  object2_1_name = arr2_1[0]
  object2_name.append(object2_1_name)

  arr2_2 = object2_2.split(" ", 2);
  object2_2_name = arr2_2[0]
  object2_name.append(object2_2_name)

  df.insert(6, 'Expansion Factor', factor)
  actual_min_distance = df['MinDistance'] / df['Expansion Factor']
  df.insert(7, 'Actual_Min_Distance', actual_min_distance)

  if enrichment_analysis == True:
    #Flag and Homer all
    df_1_all = df.loc[(df['Object1']==object1_1) & (df['Object2']==object2_1)]
    #Flag and RIM all
    df_3_all = df.loc[(df['Object1']==object1_1) & (df['Object2']== object2_2)]


    #Flag and Homer in a complex
    df_1_flag_homer_complex = df_1_all[df_1_all['Actual_Min_Distance'] < .3]
    all_flag_homer.append(df_1_all.shape[0])
    close_flag_homer.append(df_1_flag_homer_complex.shape[0])
    #Flag and RIM in a complex
    df_3_flag_rim_complex = df_3_all[df_3_all['Actual_Min_Distance'] < .3]
    all_flag_rim.append(df_3_all.shape[0])
    close_flag_rim.append(df_3_flag_rim_complex.shape[0])

    all_rim.append(df_3_all)
    all_homer.append(df_1_all)
    all_rim_complex.append(df_3_flag_rim_complex)
    all_homer_complex.append(df_1_flag_homer_complex)

  else:
    pass


  #RIM and Flag
  df_1_loc = df.loc[(df['Object1']==object1_1) & (df['Object2']==object2_1)]
  df_1_loc.drop(df_1_loc[df_1_loc['Actual_Min_Distance'] >= .3].index, inplace = True)


  #RIM and Homer
  df_2_loc = df.loc[(df['Object1']==object1_1) & (df['Object2']== object2_2)]
  df_2_loc.drop(df_2_loc[df_2_loc['Actual_Min_Distance'] >= .3].index, inplace = True)

  #Flag and Homer
  df_3_loc = df.loc[(df['Object1']==object1_2) & (df['Object2']== object2_2)]
  df_3_loc.drop(df_3_loc[df_3_loc['Actual_Min_Distance'] >= .3].index, inplace = True)

  #goes through the df_1_loc (RIM and FLag) and df_2_loc (RIM to Homer), finds the same Homer marker by SpotId and then compares the distances, both must be under 300nm
  new_data = []
  for index1, row1 in df_1_loc.iterrows():
    if row1['Actual_Min_Distance'] < 0.300:
        matching_rows = df_2_loc[
            #RIM equals to RIM index
            (df_2_loc['SpotIndex1'] == row1['SpotIndex1']) &
            (df_2_loc['Actual_Min_Distance'] < 0.300)
            ]
        for index2, row2 in matching_rows.iterrows():
            combined_data = {
                #RIM and Flag
                'Object1_df1': row1['Object1'],
                'Object2_df1': row1['Object2'],
                #RIM
                'SpotIndex_1': row1['SpotIndex1'],
                #Flag
                'ClosestSpotIndex_1': row1['ClosestSpotIndex2'],
                'Actual_Min_Distance_df1': row1['Actual_Min_Distance'],
                #RIM to Homer
                'Object1_df2': row2['Object1'],
                'Object2_df2': row2['Object2'],
                #RIM
                'SpotIndex_2': row2['SpotIndex1'],
                #Homer
                'ClosestSpotIndex_2': row2['ClosestSpotIndex2'],
                'Actual_Min_Distance_df2': row2['Actual_Min_Distance'],
            }
            new_data.append(combined_data)

  new_df = pd.DataFrame(new_data)

  #goes though df_3_loc and removes any markers by spot index that aren't in new_df, so this removes any Flag-Homer markers that aren't near a Flag
  new_data_2 = []
  # Iterate through rows of 'new_df'
  for index, row in new_df.iterrows():
    #Homer to RIM range set up
    lower_range = row['Actual_Min_Distance_df2'] - (row['Actual_Min_Distance_df2'] / 100 * 10)
    upper_range = row['Actual_Min_Distance_df2'] + (row['Actual_Min_Distance_df2'] / 100 * 10)
    # Find matching rows in 'df_3_loc' in 'ClosestSpotIndex_1' and 'ClosestSpotIndex_2'
    matching_rows_3 = df_3_loc[
    #Flag equals Flag index and Homer equals Homer index
    (df_3_loc['SpotIndex1'] == row['ClosestSpotIndex_1']) &
    (df_3_loc['ClosestSpotIndex2'] == row['ClosestSpotIndex_2']) &
    #RIM to Flag + Flag to Homer must be equal to or less than RIM to Homer
    (lower_range <= (row['Actual_Min_Distance_df1'] + df_3_loc['Actual_Min_Distance'])) &
    ((row['Actual_Min_Distance_df1'] + df_3_loc['Actual_Min_Distance']) <= upper_range)
    ]


    # Iterate through matching rows in 'df_3_loc'
    for index3, row3 in matching_rows_3.iterrows():
        # Create a dictionary to store combined data
        combined_data_2 = {
            'Object1_df3': row3['Object1'],
            'Object2_df3': row3['Object2'],
            #Flag
            'SpotIndex': row3['SpotIndex1'],
            #RIM
            'ClosestSpotIndex_3_1': row3['ClosestSpotIndex2'],
            'Actual_Min_Distance_df3': row3['Actual_Min_Distance'],
        }
        new_data_2.append(combined_data_2)

  # Create the second DataFrame from the collected data
  df_second = pd.DataFrame(new_data_2)

  filtered_data = []
  #This goes through the rows of new_df, it compares it to df_second, it removes any rows where the Flag isn't also found in df_second
  i = 0
  j = 0
  while i < len(new_df) and j < len(df_second):
    #Homer equals Homer index and Flag equals Flag
    if new_df['ClosestSpotIndex_2'].iloc[i] == df_second['ClosestSpotIndex_3_1'].iloc[j] and new_df['ClosestSpotIndex_1'].iloc[i] == df_second['SpotIndex'].iloc[j]:
      filtered_data.append(new_df.iloc[i])  # Keep the row if indices match
      i += 1
      j += 1
    else:
      i += 1
  new_df_2 = pd.DataFrame(filtered_data)

  if new_df_2.empty:
        print(f"Skipping file {file_list[n]} because new_df is empty.")
        continue  # Skip to the next file


  #merges together new_df, df_second, these will have the matching 3 proteins pairs, that are all under 300nm distance of eachother
  merged_df = pd.merge(new_df_2, df_second, left_on=['ClosestSpotIndex_2', 'ClosestSpotIndex_1'],
                     right_on=['ClosestSpotIndex_3_1', 'SpotIndex'], how='inner')


  #angle analysis
  if use_angle_analysis == True:
    #Flag to Homer
    a = merged_df['Actual_Min_Distance_df1']
    #Flag to RIM
    c = merged_df['Actual_Min_Distance_df3']
    #Homer to RIM
    b = merged_df['Actual_Min_Distance_df2']

    #anngle of flag
    merged_df['Angle_of_Homer'] = np.arccos((a**2 + b**2 - c**2) / (2 * a * b))
    merged_df['Angle_of_Homer'] = merged_df['Angle_of_Homer'].apply(math.degrees)

    #angle to RIM
    merged_df['Angle_of_RIM'] = np.arccos((c**2 + b**2 - a**2) / (2 * c * b))
    merged_df['Angle_of_RIM'] = merged_df['Angle_of_RIM'].apply(math.degrees)

    #angle of Flag
    merged_df['Angle_of_Flag'] = np.arccos((c**2 + a**2 - b**2) / (2 * c * a))
    merged_df['Angle_of_Flag'] = merged_df['Angle_of_Flag'].apply(math.degrees)

    merged_df = merged_df[(merged_df['Angle_of_Flag'] < angle_flag) & (merged_df['Angle_of_RIM'] < angle_RIM) & (merged_df['Angle_of_Homer'] < angle_Homer) & (merged_df['Angle_of_Flag'] > angle_flag_lower)]
    merged_df.drop_duplicates(inplace=True)


  #Flag and RIM
  df_1 = merged_df[['Object1_df1', 'Object2_df1', 'Actual_Min_Distance_df1']]
  df_1['range'] = pd.cut(df_1['Actual_Min_Distance_df1'], np.arange(0, .32, .02)).astype(str)
  full_range = pd.Index(pd.cut(np.arange(0, .32, .02), np.arange(0, .32, .02)).astype(str), name='range')
  df_1_grouped = df_1.groupby('range').count()
  df_1_grouped = df_1_grouped.drop('Object1_df1', axis=1)
  df_1_grouped = df_1_grouped.drop('Object2_df1', axis=1)
  df_1_grouped.rename(columns={'Actual_Min_Distance_df1': 'Actual_Min_Distance'}, inplace=True)
  df_1_grouped = df_1_grouped.reindex(full_range, fill_value=0)

  #Homer and RIM
  df_2 = merged_df[['Object1_df2', 'Object2_df2', 'Actual_Min_Distance_df2']]
  df_2['range'] = pd.cut(df_2['Actual_Min_Distance_df2'], np.arange(0, .32, .02)).astype(str)
  df_2_grouped = df_2.groupby('range').count()
  df_2_grouped = df_2_grouped.drop('Object1_df2', axis=1)
  df_2_grouped = df_2_grouped.drop('Object2_df2', axis=1)
  df_2_grouped.rename(columns={'Actual_Min_Distance_df2': 'Actual_Min_Distance'}, inplace=True)
  df_2_grouped = df_2_grouped.reindex(full_range, fill_value=0)

  #Flag and Homer
  df_3 = merged_df[['Object1_df3', 'Object2_df3', 'Actual_Min_Distance_df3']]
  df_3['range'] = pd.cut(df_3['Actual_Min_Distance_df3'], np.arange(0, .32, .02)).astype(str)
  df_3_grouped = df_3.groupby('range').count()
  df_3_grouped.rename(columns={'Actual_Min_Distance_df3': 'Actual_Min_Distance'}, inplace=True)
  df_3_grouped = df_3_grouped.drop('Object1_df3', axis=1)
  df_3_grouped = df_3_grouped.drop('Object2_df3', axis=1)
  df_3_grouped = df_3_grouped.reindex(full_range, fill_value=0)

  #Flag and Homer
  sheet_name_1 = object1_1_name + " " + object2_1_name
  #Flag and RIM
  sheet_name_2 = object1_1_name + " " + object2_2_name
  #Homer and RIM
  sheet_name_3 = object1_2_name + " " + object2_2_name

  mean1_df.append(merged_df[['Object1_df1', 'Object2_df1', 'Actual_Min_Distance_df1']])
  mean2_df.append(merged_df[['Object1_df2', 'Object2_df2', 'Actual_Min_Distance_df2']])
  mean3_df.append(merged_df[['Object1_df3', 'Object2_df3', 'Actual_Min_Distance_df3']])


  if download_range == True:
    with pd.ExcelWriter(f'{id_name}{n}_range.xlsx') as writer:
      df_1_grouped.to_excel(writer, sheet_name=sheet_name_1)
      df_2_grouped.to_excel(writer, sheet_name=sheet_name_2)
      df_3_grouped.to_excel(writer, sheet_name=sheet_name_3)
      files.download(f'{id_name}{n}_range.xlsx')
  else:
    pass

  new_data.clear()
  object1_name.clear()
  object2_name.clear()

final_mean1_df = pd.concat(mean1_df, ignore_index=True)
with pd.ExcelWriter(f'{id_name}_mean_1.xlsx') as writer:
    final_mean1_df.to_excel(writer, sheet_name='Sheet1', index=False)
    files.download(f'{id_name}_mean_1.xlsx')

final_mean2_df = pd.concat(mean2_df, ignore_index=True)
with pd.ExcelWriter(f'{id_name}_mean_2.xlsx') as writer:
    final_mean2_df.to_excel(writer, sheet_name='Sheet1', index=False)
    files.download(f'{id_name}_mean_2.xlsx')

final_mean3_df = pd.concat(mean3_df, ignore_index=True)
with pd.ExcelWriter(f'{id_name}_mean_3.xlsx') as writer:
    final_mean3_df.to_excel(writer, sheet_name='Sheet1', index=False)
    files.download(f'{id_name}_mean_3.xlsx')

if enrichment_analysis == True:
  total_all_flag_rim = sum(all_flag_rim)
  total_close_flag_rim = sum(close_flag_rim)
  total_all_flag_homer = sum(all_flag_homer)
  total_close_flag_homer = sum(close_flag_homer)

  data = {
    'Protein Interactions': proteins,
    'Total Interactions': [total_all_flag_rim, total_all_flag_homer],
    'Close Interactions': [total_close_flag_rim, total_close_flag_homer]
  }

  df_export = pd.DataFrame(data,)
  df_export.to_excel(f'{id_name}_interaction_data.xlsx')
  files.download(f'{id_name}_interaction_data.xlsx')

  merged_homer_all = pd.concat(all_homer, ignore_index=True)
  merged_rim_all = pd.concat(all_rim, ignore_index=True)
  merged_homer_complex = pd.concat(all_homer_complex, ignore_index=True)
  merged_rim_complex = pd.concat(all_rim_complex, ignore_index=True)

  with pd.ExcelWriter(f'{id_name}_raw_enrichment_data.xlsx') as writer:
      merged_homer_all.to_excel(writer, sheet_name='Flag_Homer_All', index=False)
      merged_rim_all.to_excel(writer, sheet_name='Flag_RIM_All', index=False)
      merged_homer_complex.to_excel(writer, sheet_name='Flag_Homer_Complex', index=False)
      merged_rim_complex.to_excel(writer, sheet_name='Flag_RIM_Complex', index=False)
      files.download(f'{id_name}_raw_enrichment_data.xlsx')

else:
  pass

