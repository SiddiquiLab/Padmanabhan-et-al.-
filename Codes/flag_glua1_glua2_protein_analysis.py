# -*- coding: utf-8 -*-
"""Step 1) Data_into_range_Flag_GluA1_GluA2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R9NdwmePBEshHV094NNzPvsXfBK3LMOV

Run to update

**Run to make sure program is up to date**

**Import** **Files**
"""

import pandas as pd
import numpy as np
from google.colab import data_table, files
import os
import math

"""**All data excel/xlsx files that needs to be processed should be in one folder**

id_name is the name the file will be saved as, factor is the expansion factor, folder_path is the folder name used
"""

id_name = "G91L_s1h2_2"
factor = 6.1614
folder_path = "Data"

#protein pairs for enrichment analysis if applicable
proteins = ['Flag-GluA1', 'Flag-GluA2']
range_on = False
# choose which analysis you want to include
enrichment_analysis = False
use_angle_analysis = True
#angles for each protein, angles will be lower than this value
angle_flag = 10
angle_glua1 = 180
angle_glua2 = 180

#300nm enrichment analysis lists
all_flag_glua1 = []
close_flag_glua1 = []
all_flag_glua2 = []
close_flag_glua2 = []
all_glua1 = []
all_glua2 = []
all_glua1_complex = []
all_glua2_complex = []
#lists for mean analysis
mean1_df = []
mean2_df = []
mean3_df = []
all_df_1_grouped = []
all_df_2_grouped = []
all_df_3_grouped = []

#retrieve the files from the folder_path
def get_file_names_in_folder(folder_path):

  file_names = []
  if os.path.exists(folder_path):
    for filename in os.listdir(folder_path):
      file_path = os.path.join(folder_path, filename)
      if os.path.isfile(file_path):
        file_names.append(filename)
  return file_names

file_list = get_file_names_in_folder(folder_path)
length = len(file_list)

for n in range(0,length):
  df = pd.read_csv(f'{folder_path}/{file_list[n]}')

  #retrieve the names of the protein from the dataframe
  object1_name = []
  object2_name = []

  object1 = df['Object1'].unique()

  #Flag
  object1_1 = object1[0]
  #GluA1
  object1_2 = object1[1]

  arr1_1 = object1_1.split(" ", 2);
  object1_1_name = arr1_1[0]
  object1_name.append(object1_1_name)

  arr1_2 = object1_2.split(" ", 2);
  object1_2_name = arr1_2[0]
  object1_name.append(object1_2_name)

  object2 = df['Object2'].unique()

  #GluA1
  object2_1 = object2[0]
  #GluA2
  object2_2 = object2[1]

  arr2_1 = object2_1.split(" ", 2);
  object2_1_name = arr2_1[0]
  object2_name.append(object2_1_name)

  arr2_2 = object2_2.split(" ", 2);
  object2_2_name = arr2_2[0]
  object2_name.append(object2_2_name)

  df.insert(6, 'Expansion Factor', factor)
  actual_min_distance = df['MinDistance'] / df['Expansion Factor']
  df.insert(7, 'Actual_Min_Distance', actual_min_distance)


  #enrichment analysis
  if enrichment_analysis == True:
    #Flag and glua1 all
    df_1_all = df.loc[(df['Object1']==object1_1) & (df['Object2']==object2_1)]
    #Flag and glua2 all
    df_3_all = df.loc[(df['Object1']==object1_1) & (df['Object2']== object2_2)]

    #Flag and glua1 in a complex
    df_1_flag_glua1_complex = df_1_all[df_1_all['Actual_Min_Distance'] < .3]
    all_flag_glua1.append(df_1_all.shape[0])
    close_flag_glua1.append(df_1_flag_glua1_complex.shape[0])
    #Flag and glua2 in a complex
    df_3_flag_glua2_complex = df_3_all[df_3_all['Actual_Min_Distance'] < .3]
    all_flag_glua2.append(df_3_all.shape[0])
    close_flag_glua2.append(df_3_flag_glua2_complex.shape[0])

    all_glua2.append(df_3_all)
    all_glua1.append(df_1_all)
    all_glua2_complex.append(df_3_flag_glua2_complex)
    all_glua1_complex.append(df_1_flag_glua1_complex)

  else:
    pass

  #sorting each separate protein pair into separaate dataframes

  #Flag and GluA1
  df_1_loc = df.loc[(df['Object1']==object1_1) & (df['Object2']==object2_1)]
  #df_1_loc = df_1_loc.sort_values('MinDistance').drop_duplicates('ClosestSpotIndex2', keep='first')
  df_1_loc.drop(df_1_loc[df_1_loc['Actual_Min_Distance'] >= .3].index, inplace = True)

  #GluA1 and GluA2
  df_2_loc = df.loc[(df['Object1']==object1_2) & (df['Object2']== object2_2)]
  #df_2_loc = df_2_loc.sort_values('MinDistance').drop_duplicates('ClosestSpotIndex2', keep='first')
  df_2_loc.drop(df_2_loc[df_2_loc['Actual_Min_Distance'] >= .3].index, inplace = True)

  #Flag and GluA2
  df_3_loc = df.loc[(df['Object1']==object1_1) & (df['Object2']== object2_2)]
  #df_3_loc = df_3_loc.sort_values('MinDistance').drop_duplicates('ClosestSpotIndex2', keep='first')
  df_3_loc.drop(df_3_loc[df_3_loc['Actual_Min_Distance'] >= .3].index, inplace = True)


  #goes through the df_1_loc (Flag to GluA1) and df_2_loc (GluA1 to GluA2), finds the same GluA1 marker by SpotId and then compares the distances
  #both must have the same ID and filters through under 300nm, creates a new_df with the filtered rows
  new_data = []
  for index1, row1 in df_1_loc.iterrows():
    if row1['Actual_Min_Distance'] < 0.300:
        matching_rows = df_2_loc[
            #glua1 to glua1 spot index comparision
            (df_2_loc['SpotIndex1'] == row1['ClosestSpotIndex2'])
        ]
        for index2, row2 in matching_rows.iterrows():
            combined_data = {
                'Object1_df1': row1['Object1'],
                'Object2_df1': row1['Object2'],
                'SpotIndex_1': row1['SpotIndex1'],
                'ClosestSpotIndex_1': row1['ClosestSpotIndex2'],
                'Actual_Min_Distance_df1': row1['Actual_Min_Distance'],
                'Object1_df2': row2['Object1'],
                'Object2_df2': row2['Object2'],
                'SpotIndex_2': row2['SpotIndex1'],
                'ClosestSpotIndex_2': row2['ClosestSpotIndex2'],
                'Actual_Min_Distance_df2': row2['Actual_Min_Distance'],
            }
            new_data.append(combined_data)

  new_df = pd.DataFrame(new_data)

  #iterate though df_3_loc and removes any markers by spot index that aren't in new_df
  new_data_2 = []
  #Iterate through rows of 'new_df'
  for index, row in new_df.iterrows():
      #Find matching rows in 'df_3_loc' based on 'ClosestSpotIndex_1' and 'ClosestSpotIndex_2'
      matching_rows_3 = df_3_loc[
          #flag to flag
          (df_3_loc['SpotIndex1'] == row['SpotIndex_1']) &
          #glua2 to glua2
          (df_3_loc['ClosestSpotIndex2'] == row['ClosestSpotIndex_2'])
      ]

      #Iterate through matching rows in 'df_3_loc'
      for index3, row3 in matching_rows_3.iterrows():
          # Create a dictionary to store combined data
          combined_data_2 = {
              'Object1_df3': row3['Object1'],
              'Object2_df3': row3['Object2'],
              'SpotIndex': row3['SpotIndex1'],
              'ClosestSpotIndex_3_1': row3['ClosestSpotIndex2'],
              'Actual_Min_Distance_df3': row3['Actual_Min_Distance'],
          }
          new_data_2.append(combined_data_2)
  #Create the second DataFrame from the collected data
  df_second = pd.DataFrame(new_data_2)


  filtered_data = []

  #This goes through the rows of new_df, it compares it to df_second, it removes any rows where the Flag isn't also found in df_second
  i = 0
  j = 0
  while i < len(new_df) and j < len(df_second):
    if new_df['SpotIndex_1'].iloc[i] == df_second['SpotIndex'].iloc[j] and new_df['ClosestSpotIndex_2'].iloc[i] == df_second['ClosestSpotIndex_3_1'].iloc[j]:
      filtered_data.append(new_df.iloc[i])
      i += 1
      j += 1
    else:
      i += 1
  new_df = pd.DataFrame(filtered_data)

  #if no values are found, then skip to the end of loop
  if new_df.empty:
      print(f"Skipping file {file_list[n]} because new_df is empty.")
      continue
  #merges together new_df, df_second, these will have the matching 3 proteins pairs, that are all under 300nm distance of eachother
  merged_df = pd.merge(new_df, df_second, left_on=['SpotIndex_1', 'ClosestSpotIndex_2'],
                     right_on=['SpotIndex', 'ClosestSpotIndex_3_1'], how='inner')

  #angle analysis
  if use_angle_analysis ==True:
    #Flag to GluA1 (give Flag to GluA2)
    a = merged_df['Actual_Min_Distance_df1']
    #GluA1 to GluA2
    c = merged_df['Actual_Min_Distance_df2']
    #Flag to GluA2
    b = merged_df['Actual_Min_Distance_df3']

    #angle of flag
    merged_df['Angle_of_Flag'] = np.arccos((a**2 + b**2 - c**2) / (2 * a * b))
    merged_df['Angle_of_Flag'] = merged_df['Angle_of_Flag'].apply(math.degrees)

    #angle to GluA2
    merged_df['Angle_of_GluA2'] = np.arccos((c**2 + b**2 - a**2) / (2 * c * b))
    merged_df['Angle_of_GluA2'] = merged_df['Angle_of_GluA2'].apply(math.degrees)

    #angle of GluA1
    merged_df['Angle_of_GluA1'] = np.arccos((c**2 + a**2 - b**2) / (2 * c * a))
    merged_df['Angle_of_GluA1'] = merged_df['Angle_of_GluA1'].apply(math.degrees)

    merged_df = merged_df[(merged_df['Angle_of_Flag'] < angle_flag) & (merged_df['Angle_of_GluA2'] < angle_glua2) & (merged_df['Angle_of_GluA1'] < angle_glua1)]
    merged_df.drop_duplicates(inplace=True)
  else:
    pass

  #binning of merged_df, to create a frequency distribution of the ranges
  #GluA1 and Flag
  df_1 = merged_df[['Object1_df1', 'Object2_df1', 'Actual_Min_Distance_df1']]
  df_1['range'] = pd.cut(df_1['Actual_Min_Distance_df1'], np.arange(0, .32, .02)).astype(str)
  full_range = pd.Index(pd.cut(np.arange(0, .32, .02), np.arange(0, .32, .02)).astype(str), name='range')
  df_1_grouped = df_1.groupby('range').count()
  df_1_grouped = df_1_grouped.drop('Object1_df1', axis=1)
  df_1_grouped = df_1_grouped.drop('Object2_df1', axis=1)
  df_1_grouped.rename(columns={'Actual_Min_Distance_df1': 'Actual_Min_Distance'}, inplace=True)
  df_1_grouped = df_1_grouped.reindex(full_range, fill_value=0)

  #GluA1 and GluA2
  df_2 = merged_df[['Object1_df2', 'Object2_df2', 'Actual_Min_Distance_df2']]
  df_2['range'] = pd.cut(df_2['Actual_Min_Distance_df2'], np.arange(0, .32, .02)).astype(str)
  df_2_grouped = df_2.groupby('range').count()
  df_2_grouped = df_2_grouped.drop('Object1_df2', axis=1)
  df_2_grouped = df_2_grouped.drop('Object2_df2', axis=1)
  df_2_grouped.rename(columns={'Actual_Min_Distance_df2': 'Actual_Min_Distance'}, inplace=True)
  df_2_grouped = df_2_grouped.reindex(full_range, fill_value=0)

  #Flag and GluA2
  df_3 = merged_df[['Object1_df3', 'Object2_df3', 'Actual_Min_Distance_df3']]
  df_3['range'] = pd.cut(df_3['Actual_Min_Distance_df3'], np.arange(0, .32, .02)).astype(str)
  df_3_grouped = df_3.groupby('range').count()
  df_3_grouped.rename(columns={'Actual_Min_Distance_df3': 'Actual_Min_Distance'}, inplace=True)
  df_3_grouped = df_3_grouped.drop('Object1_df3', axis=1)
  df_3_grouped = df_3_grouped.drop('Object2_df3', axis=1)
  df_3_grouped = df_3_grouped.reindex(full_range, fill_value=0)

  #GluA1 and Flag
  sheet_name_1 = object1_1_name + " " + object2_1_name
  #Flag and GluA2
  sheet_name_2 = object1_1_name + " " + object2_2_name
  #GluA1 and GluA2
  sheet_name_3 = object1_2_name + " " + object2_2_name

  mean1_df.append(merged_df[['Object1_df1', 'Object2_df1', 'Actual_Min_Distance_df1']])
  mean2_df.append(merged_df[['Object1_df2', 'Object2_df2', 'Actual_Min_Distance_df2']])
  mean3_df.append(merged_df[['Object1_df3', 'Object2_df3', 'Actual_Min_Distance_df3']])

  if range_on == True:
    #download ranges for each csv
    with pd.ExcelWriter(f'{id_name}{n}_range.xlsx') as writer:
      df_1_grouped.to_excel(writer, sheet_name=sheet_name_1)
      df_2_grouped.to_excel(writer, sheet_name=sheet_name_3)
      df_3_grouped.to_excel(writer, sheet_name=sheet_name_2)
      files.download(f'{id_name}{n}_range.xlsx')
  else:
    pass

  new_data.clear()
  object1_name.clear()
  object2_name.clear()

final_mean1_df = pd.concat(mean1_df, ignore_index=True)
with pd.ExcelWriter(f'{id_name}_mean_1.xlsx') as writer:
    final_mean1_df.to_excel(writer, sheet_name='Sheet1', index=False)
    files.download(f'{id_name}_mean_1.xlsx')

final_mean2_df = pd.concat(mean2_df, ignore_index=True)
with pd.ExcelWriter(f'{id_name}_mean_2.xlsx') as writer:
    final_mean2_df.to_excel(writer, sheet_name='Sheet1', index=False)
    files.download(f'{id_name}_mean_2.xlsx')

final_mean3_df = pd.concat(mean3_df, ignore_index=True)
with pd.ExcelWriter(f'{id_name}_mean_3.xlsx') as writer:
    final_mean3_df.to_excel(writer, sheet_name='Sheet1', index=False)
    files.download(f'{id_name}_mean_3.xlsx')

if enrichment_analysis == True:
  total_all_flag_glua1 = sum(all_flag_glua1)
  total_close_flag_glua1 = sum(close_flag_glua1)
  total_all_flag_glua2 = sum(all_flag_glua2)
  total_close_flag_glua2 = sum(close_flag_glua2)

  data = {
    'Protein Interactions': proteins,
    'Total Interactions': [total_all_flag_glua1, total_all_flag_glua2],
    'Close Interactions': [total_close_flag_glua1, total_close_flag_glua2]
  }

  df_export = pd.DataFrame(data,)
  df_export.to_excel(f'{id_name}_interaction_data.xlsx')
  files.download(f'{id_name}_interaction_data.xlsx')

  merged_glua2_all = pd.concat(all_glua2, ignore_index=True)
  merged_glua1_all = pd.concat(all_glua1, ignore_index=True)
  merged_glua2_complex = pd.concat(all_glua2_complex, ignore_index=True)
  merged_glua1_complex = pd.concat(all_glua1_complex, ignore_index=True)

  with pd.ExcelWriter(f'{id_name}_raw_enrichment_data.xlsx') as writer:
      merged_glua2_all.to_excel(writer, sheet_name='Flag_GluA2_All', index=False)
      merged_glua1_all.to_excel(writer, sheet_name='Flag_GluA1_All', index=False)
      merged_glua2_complex.to_excel(writer, sheet_name='Flag_GluA2_Complex', index=False)
      merged_glua1_complex.to_excel(writer, sheet_name='Flag_GluaA1_Complex', index=False)
      files.download(f'{id_name}_raw_enrichment_data.xlsx')

else:
  pass