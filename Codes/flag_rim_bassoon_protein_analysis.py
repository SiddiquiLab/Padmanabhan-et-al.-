# -*- coding: utf-8 -*-
"""Step 1) Data_into_range_Flag_RIM_Bassoon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cNgj6LBcBS8f87zB1E6WFSNbtaOhb7L1

Run to update

**Run to make sure program is up to date**

**Import** **Files**
"""

import pandas as pd
import numpy as np
import os
from google.colab import data_table, files
import math

"""**All data excel/xlsx files that needs to be processed should be in one folder**

id_name is the name the file will be saved as, factor is the expansion factor, folder_path is the folder name used
"""

id_name = "G93R_s3h2_SR_2_"
factor = 4.0016
folder_path = "Data"

#enrichment analysis variables
proteins = ['Flag-RIM', 'Flag-Bassoon']
enrichment_analysis = False

#angle analysis was not used in this data set
use_angle_analysis = False
angle_analysis_Flag = 180
angle_analysis_RIM = 180
angle_analysis_Bassoon = 180

flip = True
range_download = False

"""This will loop through your data folder, and create a list of file names for the program to process"""

def get_file_names_in_folder(folder_path):

  file_names = []
  if os.path.exists(folder_path):
    for filename in os.listdir(folder_path):
      file_path = os.path.join(folder_path, filename)
      if os.path.isfile(file_path):
        file_names.append(filename)
  return file_names

file_list = get_file_names_in_folder(folder_path)
length = len(file_list)

all_flag_rim = []
close_flag_rim = []
all_flag_bass = []
close_flag_bass = []

all_rim = []
all_bassoon = []
all_rim_complex = []
all_bassoon_complex = []

mean1_df = []
mean2_df = []
mean3_df = []
all_df_1_grouped = []
all_df_2_grouped = []
all_df_3_grouped = []

"""This will take all the data files, convert the distances with the expansion factor, and organize the min distances in range bins of 10nm"""

for n in range(0,length):
  df = pd.read_csv(f'{folder_path}/{file_list[n]}')

  if flip == True:
    first_object1 = df['Object1'].unique()[0]
    first_object2 = df['Object2'].unique()[0]

    filtered_df = df[(df['Object1'] == first_object1) & (df['Object2'] == first_object2)]
    filtered_df = filtered_df.rename(columns={'Object1': 'temp', 'Object2': 'Object1'})
    filtered_df = filtered_df.rename(columns={'temp': 'Object2'})
    filtered_df = filtered_df.rename(columns={'SpotIndex1': 'temp2', 'ClosestSpotIndex2': 'SpotIndex1'})
    filtered_df = filtered_df.rename(columns={'temp2': 'ClosestSpotIndex2'})
    df.update(filtered_df)

    second_object2 = df['Object2'].unique()[1]  # Get the second unique value
    filtered_df_2 = df[df['Object2'] == second_object2]
    df.loc[filtered_df_2.index] = filtered_df_2.iloc[::-1].values
  else:
    pass

  object1_name = []
  object2_name = []

  object1 = df['Object1'].unique()

  #Flag
  object1_1 = object1[0]
  #RIM
  object1_2 = object1[1]


  arr1_1 = object1_1.split(" ", 2);
  object1_1_name = arr1_1[0]
  object1_name.append(object1_1_name)

  arr1_2 = object1_2.split(" ", 2);
  object1_2_name = arr1_2[0]
  object1_name.append(object1_2_name)

  object2 = df['Object2'].unique()

  #RIM
  object2_1 = object2[0]
  #Bassoon
  object2_2 = object2[1]


  arr2_1 = object2_1.split(" ", 2);
  object2_1_name = arr2_1[0]
  object2_name.append(object2_1_name)

  arr2_2 = object2_2.split(" ", 2);
  object2_2_name = arr2_2[0]
  object2_name.append(object2_2_name)

  df.insert(6, 'Expansion Factor', factor)
  actual_min_distance = df['MinDistance'] / df['Expansion Factor']
  df.insert(7, 'Actual_Min_Distance', actual_min_distance)

  if enrichment_analysis == True:
    #Flag and Bass all
    df_1_all = df.loc[(df['Object1']==object1_1) & (df['Object2']==object2_2)]
    #Flag and RIM all
    df_3_all = df.loc[(df['Object1']==object1_1) & (df['Object2']== object2_1)]


    #Flag and Bassoon in a complex
    df_1_flag_bass_complex = df_1_all[df_1_all['Actual_Min_Distance'] < .3]
    all_flag_bass.append(df_1_all.shape[0])
    close_flag_bass.append(df_1_flag_bass_complex.shape[0])
    #Flag and RIM in a complex
    df_3_flag_rim_complex = df_3_all[df_3_all['Actual_Min_Distance'] < .3]
    all_flag_rim.append(df_3_all.shape[0])
    close_flag_rim.append(df_3_flag_rim_complex.shape[0])

    all_bassoon.append(df_1_all)
    all_rim.append(df_3_all)
    all_bassoon_complex.append(df_1_flag_bass_complex)
    all_rim_complex.append(df_3_flag_rim_complex)

  else:
    pass

  #Flag and RIM
  df_1_loc = df.loc[(df['Object1']==object1_1) & (df['Object2']==object2_1)]
  df_1_loc.drop(df_1_loc[df_1_loc['Actual_Min_Distance'] >= .3].index, inplace = True)

  #Flag and Bassoon
  df_2_loc = df.loc[(df['Object1']==object1_1) & (df['Object2']== object2_2)]
  df_2_loc.drop(df_2_loc[df_2_loc['Actual_Min_Distance'] >= .3].index, inplace = True)

  #RIM and Bassoon
  df_3_loc = df.loc[(df['Object1']==object1_2) & (df['Object2']== object2_2)]
  df_3_loc.drop(df_3_loc[df_3_loc['Actual_Min_Distance'] >= .3].index, inplace = True)



  #goes through the df_1_loc (Flag and RIM) and df_3_loc (RIM and Bassoon), finds the same Flag marker by SpotId and then compares the distances, both must be under 300nm
  new_data = []
  for index1, row1 in df_1_loc.iterrows():

    if row1['Actual_Min_Distance'] < 0.300:
        matching_rows = df_3_loc[
            #RIM index match
            (df_3_loc['SpotIndex1'] == row1['ClosestSpotIndex2'])
            ]
        for index2, row2 in matching_rows.iterrows():
            combined_data = {
                'Object1_df1': row1['Object1'],
                'Object2_df1': row1['Object2'],
                #Flag
                'SpotIndex_1': row1['SpotIndex1'],
                #RIM
                'ClosestSpotIndex_1': row1['ClosestSpotIndex2'],
                'Actual_Min_Distance_df1': row1['Actual_Min_Distance'],
                'Object1_df2': row2['Object1'],
                'Object2_df2': row2['Object2'],
                #RIM
                'SpotIndex_2': row2['SpotIndex1'],
                #Bassoon
                'ClosestSpotIndex_2': row2['ClosestSpotIndex2'],
                'Actual_Min_Distance_df2': row2['Actual_Min_Distance'],
            }
            new_data.append(combined_data)

  new_df = pd.DataFrame(new_data)

  #goes though df_2_loc and removes any markers by spot index that aren't in new_df
  new_data_2 = []
  #Iterate through rows of 'new_df'
  for index, row in new_df.iterrows():
    #Get distance of RIM to Bassoon with 10% buffer
    upper_range = row['Actual_Min_Distance_df2'] + (row['Actual_Min_Distance_df2'] / 100 * 10)
    matching_rows_3 = df_2_loc[
        #Flag index match
    (df_2_loc['SpotIndex1'] == row['SpotIndex_1']) &
        #Bassoon index match
    (df_2_loc['ClosestSpotIndex2'] == row['ClosestSpotIndex_2']) &
    ((row['Actual_Min_Distance_df1'] + df_2_loc['Actual_Min_Distance']) >= upper_range)
    ]

    #Iterate through matching rows in 'df_2_loc'
    for index3, row3 in matching_rows_3.iterrows():
        #Create a dictionary to store combined data
        combined_data_2 = {
            'Object1_df3': row3['Object1'],
            'Object2_df3': row3['Object2'],
            'SpotIndex': row3['SpotIndex1'],
            'ClosestSpotIndex_3_1': row3['ClosestSpotIndex2'],
            'Actual_Min_Distance_df3': row3['Actual_Min_Distance'],
        }
        new_data_2.append(combined_data_2)


  #Create the second DataFrame from the collected data
  df_second = pd.DataFrame(new_data_2)

  filtered_data = []

  #This goes through the rows of new_df, it compares it to df_second, it removes any rows where the Flag isn't also found in df_second
  i = 0
  j = 0
  while i < len(new_df) and j < len(df_second):
    #Flag to Flag & Bassoon to Bassoon
    if new_df['SpotIndex_1'].iloc[i] == df_second['SpotIndex'].iloc[j] and new_df['ClosestSpotIndex_2'].iloc[i] == df_second['ClosestSpotIndex_3_1'].iloc[j]:
      filtered_data.append(new_df.iloc[i])  # Keep the row if indices match
      i += 1
      j += 1
    else:
      i += 1
  new_df = pd.DataFrame(filtered_data)

  if new_df.empty:
        print(f"Skipping file {file_list[n]} because new_df is empty.")
        continue  # Skip to the next file
  else:
    pass

  merged_df = pd.merge(new_df, df_second, left_on=['SpotIndex_1', 'ClosestSpotIndex_2'],
                    right_on=['SpotIndex', 'ClosestSpotIndex_3_1'], how='inner')

  if use_angle_analysis == True:
    #Flag to RIM
    a = merged_df['Actual_Min_Distance_df1']
    #Flag to Bassoon
    c = merged_df['Actual_Min_Distance_df2']
    #RIM to Bassoon
    b = merged_df['Actual_Min_Distance_df3']

    #angle of RIM
    merged_df['Angle_of_RIM'] = np.arccos((a**2 + b**2 - c**2) / (2 * a * b))
    merged_df['Angle_of_RIM'] = merged_df['Angle_of_RIM'].apply(math.degrees)

    #angle to Bassoon
    merged_df['Angle_of_Bassoon'] = np.arccos((c**2 + b**2 - a**2) / (2 * c * b))
    merged_df['Angle_of_Bassoon'] = merged_df['Angle_of_Bassoon'].apply(math.degrees)

    #angle of Flag
    merged_df['Angle_of_Flag'] = np.arccos((c**2 + a**2 - b**2) / (2 * c * a))
    merged_df['Angle_of_Flag'] = merged_df['Angle_of_Flag'].apply(math.degrees)

    merged_df = merged_df[(merged_df['Angle_of_Flag'] < angle_analysis_Flag) & (merged_df['Angle_of_RIM'] < angle_analysis_RIM) & (merged_df['Angle_of_Bassoon'] < angle_analysis_Bassoon)]
    merged_df.drop_duplicates(inplace=True)
  else:
    pass


  #Flag and RIM
  df_1 = merged_df[['Object1_df1', 'Object2_df1', 'Actual_Min_Distance_df1']]
  df_1['range'] = pd.cut(df_1['Actual_Min_Distance_df1'], np.arange(0, .32, .02)).astype(str)
  full_range = pd.Index(pd.cut(np.arange(0, .32, .02), np.arange(0, .32, .02)).astype(str), name='range')
  df_1_grouped = df_1.groupby('range').count()
  df_1_grouped = df_1_grouped.drop('Object1_df1', axis=1)
  df_1_grouped = df_1_grouped.drop('Object2_df1', axis=1)
  df_1_grouped.rename(columns={'Actual_Min_Distance_df1': 'Actual_Min_Distance'}, inplace=True)
  df_1_grouped = df_1_grouped.reindex(full_range, fill_value=0)

  #Flag and Bass
  df_2 = merged_df[['Object1_df2', 'Object2_df2', 'Actual_Min_Distance_df2']]
  df_2['range'] = pd.cut(df_2['Actual_Min_Distance_df2'], np.arange(0, .32, .02)).astype(str)
  df_2_grouped = df_2.groupby('range').count()
  df_2_grouped = df_2_grouped.drop('Object1_df2', axis=1)
  df_2_grouped = df_2_grouped.drop('Object2_df2', axis=1)
  df_2_grouped.rename(columns={'Actual_Min_Distance_df2': 'Actual_Min_Distance'}, inplace=True)
  df_2_grouped = df_2_grouped.reindex(full_range, fill_value=0)

  #RIM and Bassoon
  df_3 = merged_df[['Object1_df3', 'Object2_df3', 'Actual_Min_Distance_df3']]
  df_3['range'] = pd.cut(df_3['Actual_Min_Distance_df3'], np.arange(0, .32, .02)).astype(str)
  df_3_grouped = df_3.groupby('range').count()
  df_3_grouped.rename(columns={'Actual_Min_Distance_df3': 'Actual_Min_Distance'}, inplace=True)
  df_3_grouped = df_3_grouped.drop('Object1_df3', axis=1)
  df_3_grouped = df_3_grouped.drop('Object2_df3', axis=1)
  df_3_grouped = df_3_grouped.reindex(full_range, fill_value=0)

  #Flag and RIM
  sheet_name_1 = object1_1_name + " " + object2_1_name
  #Flag2x and Bassoon
  sheet_name_2 = object1_1_name + " " + object2_2_name
  #RIM and Bassoon
  sheet_name_3 = object1_2_name + " " + object2_2_name

  mean1_df.append(merged_df[['Object1_df1', 'Object2_df1', 'Actual_Min_Distance_df1']])
  mean2_df.append(merged_df[['Object1_df2', 'Object2_df2', 'Actual_Min_Distance_df2']])
  mean3_df.append(merged_df[['Object1_df3', 'Object2_df3', 'Actual_Min_Distance_df3']])

  if range_download == True:
    with pd.ExcelWriter(f'{id_name}{n}_range.xlsx') as writer:
      df_1_grouped.to_excel(writer, sheet_name=sheet_name_1)
      df_2_grouped.to_excel(writer, sheet_name=sheet_name_2)
      df_3_grouped.to_excel(writer, sheet_name=sheet_name_3)
      files.download(f'{id_name}{n}_range.xlsx')
  else:
    pass

  new_data.clear()
  object1_name.clear()
  object2_name.clear()

final_mean1_df = pd.concat(mean1_df, ignore_index=True)
with pd.ExcelWriter(f'{id_name}_mean_1.xlsx') as writer:
    final_mean1_df.to_excel(writer, sheet_name='Sheet1', index=False)
    files.download(f'{id_name}_mean_1.xlsx')

final_mean2_df = pd.concat(mean2_df, ignore_index=True)
with pd.ExcelWriter(f'{id_name}_mean_2.xlsx') as writer:
    final_mean2_df.to_excel(writer, sheet_name='Sheet1', index=False)
    files.download(f'{id_name}_mean_2.xlsx')

final_mean3_df = pd.concat(mean3_df, ignore_index=True)
with pd.ExcelWriter(f'{id_name}_mean_3.xlsx') as writer:
    final_mean3_df.to_excel(writer, sheet_name='Sheet1', index=False)
    files.download(f'{id_name}_mean_3.xlsx')

if enrichment_analysis == True:
  total_all_flag_rim = sum(all_flag_rim)
  total_close_flag_rim = sum(close_flag_rim)
  total_all_flag_bass = sum(all_flag_bass)
  total_close_flag_bass = sum(close_flag_bass)

  data = {
    'Protein Interactions': proteins,
    'Total Interactions': [total_all_flag_rim, total_all_flag_bass],
    'Close Interactions': [total_close_flag_rim, total_close_flag_bass]
  }

  df_export = pd.DataFrame(data,)
  df_export.to_excel(f'{id_name}_interaction_data.xlsx')
  files.download(f'{id_name}_interaction_data.xlsx')

  merged_bass_all = pd.concat(all_bassoon, ignore_index=True)
  merged_rim_all = pd.concat(all_rim, ignore_index=True)
  merged_bass_complex = pd.concat(all_bassoon_complex, ignore_index=True)
  merged_rim_complex = pd.concat(all_rim_complex, ignore_index=True)

  with pd.ExcelWriter(f'{id_name}_raw_enrichment_data.xlsx') as writer:
      merged_bass_all.to_excel(writer, sheet_name='Flag_Bassoon_All', index=False)
      merged_rim_all.to_excel(writer, sheet_name='Flag_RIM_All', index=False)
      merged_bass_complex.to_excel(writer, sheet_name='Flag_Basson_Complex', index=False)
      merged_rim_complex.to_excel(writer, sheet_name='Flag_RIM_Complex', index=False)
      files.download(f'{id_name}_raw_enrichment_data.xlsx')

else:
  pass

